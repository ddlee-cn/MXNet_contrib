{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet.test_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_softmax(x, axis=-1):\n",
    "    # fix for old numpy on Travis not supporting keepdims\n",
    "    # x = x - np.max(x, axis=-1, keepdims=True)\n",
    "    x = x - np.max(x, axis=axis, keepdims=True)\n",
    "    x = np.exp(x)\n",
    "    # x /= np.sum(x, axis=-1, keepdims=True)\n",
    "    x /= np.sum(x, axis=axis, keepdims=True)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 0 1 3 4]\n",
      "[[ 0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.]]\n",
      "[[ 0.         -0.00838385  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          1.20303737]\n",
      " [-0.96506567  0.          0.          0.          0.        ]\n",
      " [ 0.          1.484537    0.          0.          0.        ]\n",
      " [ 0.          0.          0.          1.67262221  0.        ]\n",
      " [ 0.          0.          0.          0.         -0.54930901]]\n",
      "[-0.00838385  1.20303737 -0.96506567  1.484537    1.67262221 -0.54930901]\n"
     ]
    }
   ],
   "source": [
    "def cls2onehot(x, axis=-1):\n",
    "    # convert class ids to one hot vector\n",
    "    max_id = np.max(x)\n",
    "    original_shape = list(x.shape)\n",
    "    #print(original_shape)\n",
    "    original_shape.insert(axis+1, max_id+1)\n",
    "    #print(original_shape)\n",
    "    zero_shape = list(x.flatten().shape)\n",
    "    zero_shape.append(max_id+1)\n",
    "    # generate zeros with shape (flatten, max_id+1)\n",
    "    one_hot = np.zeros(zero_shape)\n",
    "    one_hot[np.arange(zero_shape[0]), x.flatten()] = 1\n",
    "    #print(np.sum(one_hot, axis=1))\n",
    "    zero_id = np.where(np.sum(one_hot, axis=1)==0)\n",
    "    #print(zero_id)\n",
    "    one_hot = np.reshape(one_hot, original_shape)\n",
    "    return one_hot\n",
    "\n",
    "np.random.seed(10)\n",
    "dummy = np.random.randint(0,5, [6])\n",
    "prob_dummy = np.random.normal(size=[6,5])\n",
    "print(dummy)\n",
    "one_hot = cls2onehot(dummy, 1)\n",
    "print(one_hot)\n",
    "pred_dummy = np.where(one_hot==1, prob_dummy, 0)\n",
    "print(pred_dummy)\n",
    "print(np.sum(pred_dummy, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "epsilon = 1e-16\n",
    "alpha = 0.25\n",
    "gamma = 2\n",
    "num_anchors = 5 # number of anchors per location\n",
    "num_classes  = 12 # with background as index 0\n",
    "H = 3 #height\n",
    "W = 3 #width\n",
    "N = 4 #batch size\n",
    "C = num_anchors * num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_one_hot (4, 5, 12, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "logits = np.random.normal(5, 1, [N, C, H, W])\n",
    "logits_reshape = logits.reshape([N, num_anchors, num_classes, H, W])\n",
    "label_data = np.random.randint(0, num_classes, [N, num_anchors, H, W])\n",
    "label_one_hot = cls2onehot(label_data.reshape([N, num_anchors, H, W]), 1)\n",
    "# print('logits_reshape', logits_reshape.shape)\n",
    "# print('label', label_data.shape)\n",
    "print('label_one_hot', label_one_hot.shape)\n",
    "\n",
    "prob = np_softmax(logits_reshape, axis=2) # calculate softmax output along classes axis\n",
    "#print(prob)\n",
    "#print(np.sum(prob, axis=2))\n",
    "softmax_prob = prob.reshape([N, C, H, W])\n",
    "\n",
    "preds = np.zeros([N, num_anchors, H, W])\n",
    "# take corresponding prob of class for CE loss\n",
    "for i in range(preds.shape[0]):\n",
    "    for j in range(preds.shape[1]):\n",
    "        for u in range(preds.shape[2]):\n",
    "            for v in range(preds.shape[3]):\n",
    "                cls = label_data[i][j][u][v]\n",
    "                preds[i][j][u][v] = prob[i][j][cls][u][v]\n",
    "alpha_ = np.where(label_data>=1, alpha, 1-alpha)\n",
    "\n",
    "expected_losses = -alpha_ * (1. - preds)**gamma * np.log(preds + epsilon)\n",
    "\n",
    "\n",
    "# mxnet ndarray\n",
    "x = mx.sym.Variable('x')\n",
    "label = mx.sym.Variable('label')\n",
    "norm = mx.sym.Variable('norm')\n",
    "x_nd = mx.nd.array(logits, ctx=mx.gpu(0))\n",
    "label_nd = mx.nd.array(label_data, ctx=mx.gpu(0))\n",
    "norm_nd = mx.nd.array([1], ctx=mx.gpu(0))\n",
    "\n",
    "sym = mx.sym.contrib.SoftmaxFocalLoss(data=x, label=label, normalizer=norm, \n",
    "                                        gamma=gamma, alpha=alpha, num_classes=num_classes)\n",
    "arg_shapes, out_shapes, _ = sym.infer_shape(x=x_nd.shape, label=label_nd.shape, norm=norm_nd.shape)\n",
    "args_grad = [mx.nd.empty(s, ctx=mx.gpu(0)) for s in arg_shapes]\n",
    "ex = sym.bind(ctx=mx.gpu(0), args={'x': x_nd, 'label': label_nd, 'norm': norm_nd}, args_grad=args_grad)\n",
    "ex.forward(is_train=True)\n",
    "focal_loss_out = ex.outputs[0].asnumpy()\n",
    "softmax_out = ex.outputs[1].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_almost_equal(softmax_out, softmax_prob)\n",
    "assert_almost_equal(expected_losses, focal_loss_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
